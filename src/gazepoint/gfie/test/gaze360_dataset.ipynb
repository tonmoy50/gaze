{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import Image as IPImage\n",
    "# import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional  as TF\n",
    "\n",
    "# from utils import img_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tonmoy/Library/CloudStorage/OneDrive-IndianaUniversity/Research/Education Project/Gaze/src/gazepoint/gfie/test'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUR_DIR = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "CUR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tonmoy/Library/CloudStorage/OneDrive-IndianaUniversity/Research/Education Project/Data/gaze360'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORKSPACE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(CUR_DIR)))))\n",
    "DATASET_DIR = os.path.join(WORKSPACE_DIR, \"Data\", \"gaze360\")\n",
    "DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'recordings', 'recording', 'frame', 'ts', 'target_cam', 'target_pos3d', 'target_pos2d', 'person_identity', 'person_cam', 'person_eyes3d', 'person_eyes2d', 'person_body_bbox', 'person_head_bbox', 'person_face_bbox', 'person_eye_left_bbox', 'person_eye_right_bbox', 'gaze_dir', 'splits', 'split'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = loadmat(os.path.join(CUR_DIR, \"metadata.mat\"))\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array(['rec_000'], dtype='<U7'), array(['rec_001'], dtype='<U7'),\n",
       "        array(['rec_002'], dtype='<U7'), array(['rec_003'], dtype='<U7'),\n",
       "        array(['rec_004'], dtype='<U7'), array(['rec_005'], dtype='<U7'),\n",
       "        array(['rec_006'], dtype='<U7'), array(['rec_007'], dtype='<U7'),\n",
       "        array(['rec_008'], dtype='<U7'), array(['rec_009'], dtype='<U7'),\n",
       "        array(['rec_010'], dtype='<U7'), array(['rec_011'], dtype='<U7'),\n",
       "        array(['rec_012'], dtype='<U7'), array(['rec_013'], dtype='<U7'),\n",
       "        array(['rec_014'], dtype='<U7'), array(['rec_015'], dtype='<U7'),\n",
       "        array(['rec_016'], dtype='<U7'), array(['rec_017'], dtype='<U7'),\n",
       "        array(['rec_018'], dtype='<U7'), array(['rec_019'], dtype='<U7'),\n",
       "        array(['rec_020'], dtype='<U7'), array(['rec_021'], dtype='<U7'),\n",
       "        array(['rec_022'], dtype='<U7'), array(['rec_023'], dtype='<U7'),\n",
       "        array(['rec_024'], dtype='<U7'), array(['rec_025'], dtype='<U7'),\n",
       "        array(['rec_026'], dtype='<U7'), array(['rec_027'], dtype='<U7'),\n",
       "        array(['rec_028'], dtype='<U7'), array(['rec_029'], dtype='<U7'),\n",
       "        array(['rec_030'], dtype='<U7'), array(['rec_031'], dtype='<U7'),\n",
       "        array(['rec_032'], dtype='<U7'), array(['rec_033'], dtype='<U7'),\n",
       "        array(['rec_034'], dtype='<U7'), array(['rec_035'], dtype='<U7'),\n",
       "        array(['rec_036'], dtype='<U7'), array(['rec_037'], dtype='<U7'),\n",
       "        array(['rec_038'], dtype='<U7'), array(['rec_039'], dtype='<U7'),\n",
       "        array(['rec_040'], dtype='<U7'), array(['rec_041'], dtype='<U7'),\n",
       "        array(['rec_042'], dtype='<U7'), array(['rec_043'], dtype='<U7'),\n",
       "        array(['rec_044'], dtype='<U7'), array(['rec_045'], dtype='<U7'),\n",
       "        array(['rec_046'], dtype='<U7'), array(['rec_047'], dtype='<U7'),\n",
       "        array(['rec_048'], dtype='<U7'), array(['rec_049'], dtype='<U7'),\n",
       "        array(['rec_050'], dtype='<U7'), array(['rec_051'], dtype='<U7'),\n",
       "        array(['rec_052'], dtype='<U7'), array(['rec_053'], dtype='<U7'),\n",
       "        array(['rec_054'], dtype='<U7'), array(['rec_055'], dtype='<U7'),\n",
       "        array(['rec_056'], dtype='<U7'), array(['rec_057'], dtype='<U7'),\n",
       "        array(['rec_058'], dtype='<U7'), array(['rec_059'], dtype='<U7'),\n",
       "        array(['rec_060'], dtype='<U7'), array(['rec_061'], dtype='<U7'),\n",
       "        array(['rec_062'], dtype='<U7'), array(['rec_063'], dtype='<U7'),\n",
       "        array(['rec_064'], dtype='<U7'), array(['rec_065'], dtype='<U7'),\n",
       "        array(['rec_066'], dtype='<U7'), array(['rec_067'], dtype='<U7'),\n",
       "        array(['rec_068'], dtype='<U7'), array(['rec_069'], dtype='<U7'),\n",
       "        array(['rec_070'], dtype='<U7'), array(['rec_071'], dtype='<U7'),\n",
       "        array(['rec_072'], dtype='<U7'), array(['rec_073'], dtype='<U7'),\n",
       "        array(['rec_074'], dtype='<U7'), array(['rec_075'], dtype='<U7'),\n",
       "        array(['rec_076'], dtype='<U7'), array(['rec_077'], dtype='<U7'),\n",
       "        array(['rec_078'], dtype='<U7'), array(['rec_079'], dtype='<U7')]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"recordings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 79, 79, 79], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"recording\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2, ..., 521, 522, 522]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.12525296,  0.25050497, ..., 63.37850809,\n",
       "        63.50351596, 63.50351596]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"ts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"person_identity\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.69389339,  1.75942589, -0.62393989],\n",
       "       [ 1.68793889,  1.76528217, -0.62475749],\n",
       "       [ 1.68868502,  1.76575734, -0.62507184],\n",
       "       ...,\n",
       "       [ 0.67011673, -0.48928031, -0.51240202],\n",
       "       [ 0.64817876, -0.47156056, -0.44699191],\n",
       "       [ 0.64817876, -0.47156056, -0.44699191]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"target_pos3d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58718794, 0.4859066 , 0.04633445, 0.0382576 ],\n",
       "       [0.5837803 , 0.48372877, 0.04876879, 0.04026759],\n",
       "       [0.5783111 , 0.47928429, 0.05532767, 0.04568315],\n",
       "       ...,\n",
       "       [0.51265723, 0.47321415, 0.08451395, 0.06978178],\n",
       "       [0.49715102, 0.47933304, 0.08145172, 0.06725335],\n",
       "       [0.51202176, 0.47195637, 0.08704371, 0.07187057]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"person_head_bbox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(mat, dstype):\n",
    "    orig_x, orig_y = 3382, 4096\n",
    "    frame = mat[\"frame\"]\n",
    "    # person_eyes_2d = mat[\"person_eyes2d\"]\n",
    "    # person_eyes_3d = mat[\"person_eyes3d\"]\n",
    "\n",
    "    himg = list()\n",
    "    simg = list()\n",
    "    frame_id = list()\n",
    "    hbbox = list()\n",
    "    fbbox = list()\n",
    "    bbbox = list()\n",
    "    person_eyes2d = list()\n",
    "    person_eyes3d = list()\n",
    "    gaze_direction = list()\n",
    "    target2d = list()\n",
    "    target3d = list()\n",
    "\n",
    "\n",
    "    for i in range(len(frame[0])):\n",
    "        if  mat[\"split\"][0][i] == dstype:\n",
    "            himg += [os.path.join(\n",
    "                mat[\"recordings\"][0][mat[\"recording\"][0][i]].item(),\n",
    "                \"head\",\n",
    "                \"%06d\" % mat[\"person_identity\"][0][i].item(),\n",
    "                \"%06d.jpg\" % mat[\"frame\"][0][i].item(),\n",
    "            )]\n",
    "            simg += [os.path.join(\n",
    "                mat[\"recordings\"][0][mat[\"recording\"][0][i]].item(),\n",
    "                \"body\",\n",
    "                \"%06d\" % mat[\"person_identity\"][0][i].item(),\n",
    "                \"%06d.jpg\" % mat[\"frame\"][0][i].item(),\n",
    "            )]\n",
    "            frame_id += [mat[\"frame\"][0][i]]\n",
    "            hbbox += [mat[\"person_head_bbox\"][i]]\n",
    "            # fbbox += [mat[\"person_face_bbox\"][i]]\n",
    "            # bbbox += [mat[\"person_body_bbox\"][i]]\n",
    "            person_eyes2d += [mat[\"person_eyes2d\"][i]]\n",
    "            person_eyes3d += [mat[\"person_eyes3d\"][i]]\n",
    "            gaze_direction += [mat[\"gaze_dir\"][i]]\n",
    "            target2d += [mat[\"target_pos2d\"][i]]\n",
    "            target3d += [mat[\"target_pos3d\"][i]]\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"simg\": simg,\n",
    "        \"himg\": himg,\n",
    "        \"frame_id\": frame_id,\n",
    "        \"h_x_min\" : [x[0] for x in hbbox],\n",
    "        \"h_y_min\" : [x[1] for x in hbbox],\n",
    "        \"h_x_max\" : [x[2] for x in hbbox],\n",
    "        \"h_y_max\" : [x[3] for x in hbbox],\n",
    "        \"eye_u\" : [x[0] for x in person_eyes2d],\n",
    "        \"eye_v\" : [x[1] for x in person_eyes2d],\n",
    "        \"eye_X\" : [x[0] for x in person_eyes3d],\n",
    "        \"eye_Y\" : [x[1] for x in person_eyes3d],\n",
    "        \"eye_Z\" : [x[2] for x in person_eyes3d],\n",
    "        \"gaze_dirX\": [x[0] for x in gaze_direction],\n",
    "        \"gaze_dirY\": [x[1] for x in gaze_direction],\n",
    "        \"gaze_dirZ\": [x[2] for x in gaze_direction],\n",
    "        \"gaze_u\" : [x[0] for x in target2d],\n",
    "        \"gaze_v\": [x[1] for x in target2d],\n",
    "        \"gaze_X\": [x[0] for x in target3d],\n",
    "        \"gaze_Y\": [x[1] for x in target3d],\n",
    "        \"gaze_Z\": [x[2] for x in target3d],\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126928, 20)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepare Train Dataset\n",
    "df = prepare_dataset(mat, 0)\n",
    "df.to_csv(os.path.join(DATASET_DIR, \"train.csv\"))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17038, 20)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepare Validation Dataset\n",
    "df = prepare_dataset(mat, 1)\n",
    "df.to_csv(os.path.join(DATASET_DIR, \"validation.csv\"))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25969, 20)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepare Test Dataset\n",
    "df = prepare_dataset(mat, 2)\n",
    "df.to_csv(os.path.join(DATASET_DIR, \"test.csv\"))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = os.path.join(DATASET_DIR, \"imgs\", mat[\"recordings\"]) # , \"body\", '%06d' % mat[\"person_identity\"][0], \"%06d.jpg\" % mat[\"frame\"][0]\n",
    "# img_path\n",
    "orig_x, orig_y = 3382, 4096\n",
    "recordings = mat[\"recordings\"]\n",
    "recording = mat[\"recording\"]\n",
    "splits = mat[\"splits\"]\n",
    "split = mat[\"split\"]\n",
    "person_head_bbox = mat[\"person_head_bbox\"]\n",
    "person_face_bbox = mat[\"person_face_bbox\"]\n",
    "person_body_bbox = mat[\"person_body_bbox\"]\n",
    "person_identity = mat[\"person_identity\"]\n",
    "gaze_dir = mat[\"gaze_dir\"]\n",
    "frame = mat[\"frame\"]\n",
    "person_eyes_2d = mat[\"person_eyes_2d\"]\n",
    "person_eyes_3d = mat[\"person_eyes_3d\"]\n",
    "\n",
    "i = 7370\n",
    "img_path = os.path.join(\n",
    "    DATASET_DIR,\n",
    "    \"imgs\",\n",
    "    recordings[0][recording[0][i]].item(),\n",
    "    \"head\",\n",
    "    \"%06d\" % mat[\"person_identity\"][0][i].item(),\n",
    "    \"%06d.jpg\" % mat[\"frame\"][0][i].item(),\n",
    ")\n",
    "# img_path\n",
    "# img = Image.open(img_path)\n",
    "# Image._show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "checkpoint = \"vinvino02/glpn-nyu\"\n",
    "depth_estimator = pipeline(\"depth-estimation\", model=checkpoint, device=0)\n",
    "\n",
    "sample_img = Image.open(os.path.join(DATASET_DIR, \"imgs\", lines[0].split(\" \")[0]))\n",
    "preds = depth_estimator(sample_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 217)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_depth': tensor([[[5.3033, 5.9054, 5.7112,  ..., 4.9678, 5.0379, 5.1203],\n",
       "          [6.2931, 7.2684, 7.4032,  ..., 4.8657, 5.0426, 4.9449],\n",
       "          [6.5597, 7.6745, 7.8852,  ..., 5.2611, 5.4131, 5.0675],\n",
       "          ...,\n",
       "          [3.2218, 3.0695, 2.8769,  ..., 5.6232, 5.4847, 5.1200],\n",
       "          [3.4083, 3.1831, 2.9930,  ..., 5.5539, 5.3422, 5.0289],\n",
       "          [3.8051, 3.6194, 3.3994,  ..., 5.2701, 5.1984, 4.9153]]]),\n",
       " 'depth': <PIL.Image.Image image mode=L size=217x217>}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 192, 192]), (217, 217))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[\"predicted_depth\"].shape, preds[\"depth\"].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "cam_kinect = np.array([910.78759766, 910.21258545, 961.65966797, 554.11016846])\n",
    "np.save(os.path.join(DATASET_DIR, \"CameraKinect.npy\"), cam_kinect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaze",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
